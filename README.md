# ECCB2022

Shorten Link: http://bit.ly/eccb2022

ECCB web: https://eccb2022.org/ntb-t03/

## Slides
https://docs.google.com/presentation/d/1zAcJcWtyA-kh7AP_Hy_7OuzjQigppFaG74hLejJVlD8/edit?usp=sharing

## Colab notebooks with exercises

1. **Exercise 1**: MNIST with fully connected network [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/01_MNIST_Dense_layers.ipynb)

2. **Exercise 2**: Fine tuning CNN model to your own data [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/02_Fine_tuning_CNN_model_to_your_own_data.ipynb)

3. **Exercise 3**: Transformers and transfer learning [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/03_Transformers_and_transfer_learning.ipynb)

4. **Exercise 4**: Gradio demo [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/04_Gradio_app_and_HF_spaces.ipynb)

5. **Extra exercise** (not presented during the tutorial): CNN for genomic sequences - basics [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/05a_CNN_for_sequences_basics.ipynb), fastai [[open]](https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/05b_CNN_for_sequences_fastai.ipynb)

## Additional materials

Where to go next:

1. **Fast.ai** - [course](https://course.fast.ai/), [library](https://docs.fast.ai/)

2. ðŸ¤— - [course](https://huggingface.co/course/chapter1/1), [datasets](https://huggingface.co/datasets), [models](https://huggingface.co/models), [spaces](https://huggingface.co/spaces), [libraries](https://huggingface.co/docs)

3. **Genomic benchmarks** - [repo](https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks) with genomic datasets, [preprint](https://www.biorxiv.org/content/10.1101/2022.06.08.495248v1.full)

4. **Transformers** - [Stanford course on transformers](https://www.youtube.com/watch?v=P127jhj-8-Y), [DeepMind paper](https://arxiv.org/abs/2207.09238) on algorithms

5. **Transformers on genomic and proteomic sequences**:
    - [DNABert paper](https://www.biorxiv.org/content/10.1101/2020.09.17.301879v1) - language model trained on genome
    - [AlphaFold2 paper](https://www.nature.com/articles/s42003-022-03269-0)
    - [ESM2 paper](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1) - language model trained on proteome
    - [ML Protein Engineering Seminar Series](https://www.ml4proteinengineering.com/schedule)
