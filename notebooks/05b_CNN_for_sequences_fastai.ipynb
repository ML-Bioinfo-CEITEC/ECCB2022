{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBweibfvNoB6FeM3jT4Ii8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-Bioinfo-CEITEC/ECCB2022/blob/main/notebooks/05b_CNN_for_sequences_fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime -> Change runtime type -> GPU"
      ],
      "metadata": {
        "id": "VOiGwOcUfazY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets torchmetrics --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhxLEguoXNNa",
        "outputId": "a0033599-9c20-49ac-dac0-5baa6996ec86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 365 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 64.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 40.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "nucleotide_to_number = {\n",
        "    'A':0,\n",
        "    'C':1,\n",
        "    'T':2,\n",
        "    'G':3,\n",
        "    'N':4,\n",
        "}\n",
        "\n",
        "def numericalize(x, vocab):\n",
        "  x = [vocab[s] for s in x]\n",
        "  return x"
      ],
      "metadata": {
        "id": "8YrdPyqf9BL0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function that takes multiple raw samples, and prepares them for the neural network.\n",
        "\n",
        "This will \n",
        "- numericalize\n",
        "- one hot encode\n",
        "- put data to tensors (needed for pytorch models)"
      ],
      "metadata": {
        "id": "1aE5ElTe5N5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(batch):\n",
        "  xs, ys = [], []\n",
        "  for example in batch:\n",
        "    x = example['seq']\n",
        "    y = example['labels']\n",
        "\n",
        "    x = numericalize(x, vocab=nucleotide_to_number)\n",
        "    x = F.one_hot(torch.tensor(x), num_classes = 5).float()\n",
        "    x = x.transpose(0,1)\n",
        "\n",
        "    xs.append(x)\n",
        "    ys.append([y])\n",
        "  \n",
        "  return torch.stack(xs), torch.tensor(ys).float()"
      ],
      "metadata": {
        "id": "YJ0czKVF4S2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know how to improve on one example. \n",
        "\n",
        "We could just go through the dataset and improve a little bit on each single one of the sequences. (improve on 1st, then on 2nd, then on 3rd....)\n",
        "\n",
        "In practice, we usually try to improve on a whole 'batch' of sequences at once. (improve on samples 1-100, then on 101-200,...)\n",
        "\n",
        "In practice, this makes the learning process go much faster, and improves generalizability."
      ],
      "metadata": {
        "id": "TuzSidiW4nZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "\n",
        "train_dset = load_dataset(\"simecek/human_nontata_promoters\", split=\"train\")\n",
        "test_dset = load_dataset(\"simecek/human_nontata_promoters\", split=\"test\")\n",
        "\n",
        "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True, collate_fn=preprocess)  \n",
        "test_loader = DataLoader(test_dset, batch_size=32, collate_fn=preprocess)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVXa5tpzBgeu",
        "outputId": "9dc69de1-1e90-430f-f8c9-7f9fa422fe8f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration simecek--human_nontata_promoters-5bc25970767ab8f4\n",
            "WARNING:datasets.builder:Reusing dataset parquet (/root/.cache/huggingface/datasets/simecek___parquet/simecek--human_nontata_promoters-5bc25970767ab8f4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "WARNING:datasets.builder:Using custom data configuration simecek--human_nontata_promoters-5bc25970767ab8f4\n",
            "WARNING:datasets.builder:Reusing dataset parquet (/root/.cache/huggingface/datasets/simecek___parquet/simecek--human_nontata_promoters-5bc25970767ab8f4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will wrap our architecture so its ready for the training"
      ],
      "metadata": {
        "id": "S_G5dPGB6LHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT4Z9-p-zgiQ",
        "outputId": "9adc1987-7e8e-4820-feaa-c585f2482e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class FullyConv(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.net = nn.Sequential(\n",
        "          nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, kernel_size=5, stride=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=5, stride=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Flatten(),\n",
        "          nn.LazyLinear(out_features=output_dim), #Lazy layer allows us to skip the in_features parameter and derive it automatically\n",
        "          nn.Sigmoid(),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n",
        "net = FullyConv(5,30,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most basic training through the whole dataset goes like this:\n",
        "\n",
        "```\n",
        "for each batch in data_loader:\n",
        "  model.learn_from(batch)\n",
        "```\n",
        "\n",
        "In practice, we iterate through the same dataset multiple times, since we are improving in small steps. \n",
        "\n",
        "Going through the whole dataset is called an epoch.\n",
        "\n",
        "\n",
        "```\n",
        "for i in range(number_of_epochs):\n",
        "  for each batch in data_loader:\n",
        "    model.learn_from(batch)\n",
        "```\n",
        "\n",
        "This is exactly what a Trainer/Learner does.\n"
      ],
      "metadata": {
        "id": "0EONxsgr6d92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "acc = Accuracy()#.to('cuda')\n",
        "def test_accuracy(x,y):\n",
        "  return acc(x, y.int())"
      ],
      "metadata": {
        "id": "mSQP64kdT6JT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *\n",
        "\n",
        "data = DataLoaders(train_loader, test_loader)\n",
        "learn = Learner(data, net, loss_func=F.binary_cross_entropy, opt_func=SGD, metrics=[test_accuracy])"
      ],
      "metadata": {
        "id": "7o6UtCoM9ehW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(3, 1e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "0HSjh6Tq9yUB",
        "outputId": "227dfb07-54fc-46f0-f453-488359de168e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.499127</td>\n",
              "      <td>0.504473</td>\n",
              "      <td>0.760793</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.458048</td>\n",
              "      <td>0.461305</td>\n",
              "      <td>0.780607</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.436222</td>\n",
              "      <td>0.454155</td>\n",
              "      <td>0.784038</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}